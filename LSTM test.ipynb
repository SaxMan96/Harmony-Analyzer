{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"songs_and_chords.csv\")\n",
    "data = [ast.literal_eval(chords_string) for chords_string in df[\"encoded_chords\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove too short songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "SAMPLE_LEN = 8\n",
    "data = [chords for chords in data if len(chords)>SAMPLE_LEN]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling dataset 8 chords before and 9'th cord as a value to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103631, 7, 12) (103631, 12)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for chords in data:\n",
    "    for i in range(len(chords)):\n",
    "        if i < len(chords) - SAMPLE_LEN:\n",
    "            x.append(chords[i : i + SAMPLE_LEN - 1])\n",
    "        else:\n",
    "            x.append(chords[i : len(chords) - 1] + chords[: (i + SAMPLE_LEN) % len(chords)])\n",
    "        y.append(chords[(i + SAMPLE_LEN) % len(chords)])    \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'music21'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b52a06cb1175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmusic21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchord\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'music21'"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "for chord in x_samples[0]:\n",
    "    print(len(chord))\n",
    "    print(type(list(chord)))\n",
    "    print(chord)\n",
    "    # decode\n",
    "#     music21.chord.Chord([1,2,3])\n",
    "    break\n",
    "# names = [music21.chord.Chord(list(chord)).commonName for chord in x_samples[0]]\n",
    "# print(names)\n",
    "# print(music21.chord.Chord(y_samples[0]).commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short-Term Memory, or LSTM, recurrent neural networks expect three-dimensional input in the Keras Python deep learning library.\n",
    "LSTMs expect 3D input, and it can be challenging to get your head around this the first time.\n",
    "LSTMs donâ€™t like sequences of more than 200-400 time steps, so the data will need to be split into samples.\n",
    "\n",
    "If you have a long sequence of thousands of observations in your time series data, you must split your time series into samples and then reshape it for your LSTM model.\n",
    "\n",
    "The LSTM needs data with the format of [samples, time steps and features]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The LSTM input layer must be 3D.\n",
    "- The meaning of the 3 input dimensions are: samples, time steps, and features.\n",
    "- The LSTM input layer is defined by the input_shape argument on the first hidden layer.\n",
    "- The input_shape argument takes a tuple of two values that define the number of time steps and features.\n",
    "- The number of samples is assumed to be 1 or more.\n",
    "- The reshape() function on NumPy arrays can be used to reshape your 1D or 2D data to be 3D.\n",
    "- The reshape() function takes a tuple as an argument that defines the new shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(7, 12)))\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=8)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 32)                5760      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 6,156\n",
      "Trainable params: 6,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(loaded_model.summary())\n",
    "scores = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-env]",
   "language": "python",
   "name": "conda-env-tf-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
