{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"songs_and_chords.csv\")\n",
    "data = [ast.literal_eval(chords_string) for chords_string in df[\"encoded_chords\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove too short songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "SAMPLE_LEN = 8\n",
    "data = [chords for chords in data if len(chords)>SAMPLE_LEN]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling dataset 8 chords before and 9'th cord as a value to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 7, 12) (36, 12)\n",
      "12\n",
      "<class 'list'>\n",
      "[1 0 1 1 0 1 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_samples = []\n",
    "y_samples = []\n",
    "for chords in [data[5]]:\n",
    "    for i in range(len(chords)):\n",
    "        if i < len(chords) - SAMPLE_LEN:\n",
    "            x_samples.append(chords[i : i + SAMPLE_LEN - 1])\n",
    "        else:\n",
    "            x_samples.append(chords[i : len(chords) - 1] + chords[: (i + SAMPLE_LEN) % len(chords)])\n",
    "        y_samples.append(chords[(i + SAMPLE_LEN) % len(chords)])    \n",
    "    break\n",
    "x_samples = np.array(x_samples)\n",
    "y_samples = np.array(y_samples)\n",
    "print(x_samples.shape, y_samples.shape)\n",
    "import music21\n",
    "for chord in x_samples[0]:\n",
    "    print(len(chord))\n",
    "    print(type(list(chord)))\n",
    "    print(chord)\n",
    "    # decode\n",
    "#     music21.chord.Chord([1,2,3])\n",
    "    break\n",
    "# names = [music21.chord.Chord(list(chord)).commonName for chord in x_samples[0]]\n",
    "# print(names)\n",
    "# print(music21.chord.Chord(y_samples[0]).commonName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short-Term Memory, or LSTM, recurrent neural networks expect three-dimensional input in the Keras Python deep learning library.\n",
    "LSTMs expect 3D input, and it can be challenging to get your head around this the first time.\n",
    "LSTMs donâ€™t like sequences of more than 200-400 time steps, so the data will need to be split into samples.\n",
    "\n",
    "If you have a long sequence of thousands of observations in your time series data, you must split your time series into samples and then reshape it for your LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 274s 11ms/sample - loss: 0.4941 - acc: 0.7412\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 274s 11ms/sample - loss: 0.3013 - acc: 0.8779\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 277s 11ms/sample - loss: 0.2611 - acc: 0.9004\n",
      "Accuracy: 86.56%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
