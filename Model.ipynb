{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utilities import *\n",
    "from music21.harmony import chordSymbolFigureFromChord as figureChord\n",
    "from music21.chord import Chord\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM requirements:\n",
    "\n",
    "- The LSTM input layer must be 3D.\n",
    "- LSTMs donâ€™t like sequences of more than 200-400 time steps, so the data will need to be split into samples.\n",
    "- If you have a long sequence of thousands of observations, you must split it into samples and then reshape it for your LSTM model.\n",
    "- The LSTM needs data with the format of [samples, time steps and features].\n",
    "- The LSTM input layer is defined by the input_shape argument on the first hidden layer.\n",
    "- The input_shape argument takes a tuple of two values that define the number of time steps and features.\n",
    "- The number of samples is assumed to be 1 or more.\n",
    "- The reshape() function on NumPy arrays can be used to reshape your 1D or 2D data to be 3D.\n",
    "- The reshape() function takes a tuple as an argument that defines the new shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "import utilities as my_utils\n",
    "ft = FastText.load(\"./embeddings/fastText.model\")\n",
    "songs = my_utils.build_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(songs, sample_len = 4):\n",
    "    # Remove too short songs\n",
    "    songs = [chords for chords in songs if len(chords) > sample_len]\n",
    "    x = []\n",
    "    y = []\n",
    "    for chords in songs:\n",
    "        for i in range(len(chords)):\n",
    "            if i < len(chords) - SAMPLE_LEN:\n",
    "                x.append(chords[i: i + SAMPLE_LEN - 1])\n",
    "            else:\n",
    "                x.append(\n",
    "                    chords[i: len(chords) - 1]\n",
    "                    + chords[: (i + SAMPLE_LEN) % len(chords)]\n",
    "                )\n",
    "            y.append(chords[(i + SAMPLE_LEN) % len(chords)])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "X, y = prep_data(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243944, 3, 64) (1243944, 64) (1243944, 3) (1243944,)\n"
     ]
    }
   ],
   "source": [
    "def encode_chords(X, y, model):\n",
    "    X_embedded = []\n",
    "    y_embedded = []\n",
    "    for X_sapmle, y_sapmle in zip(X, y):\n",
    "        X_embedded.append(model.wv[X_sapmle])\n",
    "        y_embedded.append(model.wv[y_sapmle])\n",
    "    X_embedded = np.array(X_embedded)\n",
    "    y_embedded = np.array(y_embedded)\n",
    "    return X_embedded, y_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, X_train, y_test = train_test_split(X_embedded, y_embedded, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.82 2.67 1.11 -1.31 -0.172 0.652 0.501 -1.35 -1.25 0.533 0.434 -0.0232 1.74 -0.362 -2.12 1.63 -1.46 0.598 -0.459 0.809 0.9 3.27 0.758 -2.99 0.793 -0.149 -0.986 -0.328 1.69 -0.752 -0.222 0.957 1.51 -1.28 0.333 1.04 -1.94 -1.66 -0.0551 -0.472 0.308 -0.306 -0.376 0.757 -1.05 -1.13 1.27 -2.23 2.5 -2.14 0.851 0.242 1.61 1.61 -1.38 1.08 0.17 -1.02 -0.448 0.032 1.2 2.13 0.238 -2.02]\n"
     ]
    }
   ],
   "source": [
    "print(y_embedded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        LSTM(64, input_shape=X_train.shape[1:]),\n",
    "        Dense(y_train.shape[1], activation='sigmoid')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(keras.callbacks.Callback):\n",
    "    def __init__(embedding):\n",
    "        self.embedding = embedding\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self._data = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        y_predict = np.asarray(model.predict(X_val))\n",
    "\n",
    "        y_val = np.argmax(y_val, axis=1)\n",
    "        y_predict = np.argmax(y_predict, axis=1)\n",
    "\n",
    "        self._data.append({\n",
    "            'val_rocauc': roc_auc_score(y_val, y_predict),\n",
    "        })\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 37,184\n",
      "Trainable params: 37,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "80000/80000 [==============================] - 13s 166us/sample - loss: 1.8671 - tp: 876017.0000 - fp: 0.0000e+00 - tn: 0.0000e+00 - fn: 4243983.0000 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.1711 - auc: 0.0000e+00 - val_loss: 1.8667 - val_tp: 224670.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1055330.0000 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 0.1755 - val_auc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "80000/80000 [==============================] - 3s 44us/sample - loss: 1.8553 - tp: 910904.0000 - fp: 0.0000e+00 - tn: 0.0000e+00 - fn: 4209096.0000 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.1779 - auc: 0.0000e+00 - val_loss: 1.8573 - val_tp: 230723.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1049277.0000 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 0.1803 - val_auc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "80000/80000 [==============================] - 3s 44us/sample - loss: 1.8459 - tp: 956981.0000 - fp: 0.0000e+00 - tn: 0.0000e+00 - fn: 4163019.0000 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.1869 - auc: 0.0000e+00 - val_loss: 1.8482 - val_tp: 248049.0000 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 1031951.0000 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 0.1938 - val_auc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.25\n",
    "epochs = 20\n",
    "batch_size = 500\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "METRICS_NAMES = [\n",
    "    \"loss\",\n",
    "    \"tp\",\n",
    "    \"fp\",\n",
    "    \"tn\",\n",
    "    \"fn\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"auc\",\n",
    "]\n",
    "loss = keras.losses.MeanSquaredError() \n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss=loss, batch_size=batch_size, optimizer=optimizer, metrics=METRICS)\n",
    "print(model.summary())\n",
    "history = model.fit(X_train[:100000], y_train[:100000], epochs=3, batch_size=1000, validation_split=0.2).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8670565992593766, 1.8553203254938126, 1.8459146738052368],\n",
       " 'tp': [876017.0, 910904.0, 956981.0],\n",
       " 'fp': [0.0, 0.0, 0.0],\n",
       " 'tn': [0.0, 0.0, 0.0],\n",
       " 'fn': [4243983.0, 4209096.0, 4163019.0],\n",
       " 'accuracy': [0.0, 0.0, 0.0],\n",
       " 'precision': [1.0, 1.0, 1.0],\n",
       " 'recall': [0.17109707, 0.17791094, 0.18691035],\n",
       " 'auc': [0.0, 0.0, 0.0],\n",
       " 'val_loss': [1.866728091239929, 1.857328337430954, 1.8482354521751403],\n",
       " 'val_tp': [224670.0, 230723.0, 248049.0],\n",
       " 'val_fp': [0.0, 0.0, 0.0],\n",
       " 'val_tn': [0.0, 0.0, 0.0],\n",
       " 'val_fn': [1055330.0, 1049277.0, 1031951.0],\n",
       " 'val_accuracy': [0.0, 0.0, 0.0],\n",
       " 'val_precision': [1.0, 1.0, 1.0],\n",
       " 'val_recall': [0.17552343, 0.18025234, 0.19378828],\n",
       " 'val_auc': [0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 37,184\n",
      "Trainable params: 37,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-maj7/C  | A#m7/C#  | A-maj7/C  | Fm7/C\n",
      "Fm/C  | Fm/C  | C7  | Fm/CaddB-\n",
      "Gm/D  | B-7/D  | Fm/C  | Gm7/D\n",
      "E-  | A-7/C  | A-7/C  | A-/CaddA\n",
      "Gm7/D  | C7  | F/C  | F/CaddB-\n",
      "E-  | Gm/D  | Cm  | Cm7\n",
      "C7  | F-+/CaddB-  | F/C  | B-/C\n",
      "B-/D  | E-+  | C7  | Chord Symbol Cannot Be Identified\n",
      "F7/C  | B-/D  | B-/D  | B-/C\n",
      "E-m  | A#m7/C#  | E-m  | Chord Symbol Cannot Be Identified\n",
      "Gm7/D  | C7  | F/C  | B-/C\n",
      "D/o7/C  | E-+addF  | Cm7  | B-/C\n",
      "F9/CaddB  | B-7/D  | Cm7addD-,A-,F  | D-maj7/C\n",
      "A7/C#  | D7/C  | D7/C  | Chord Symbol Cannot Be Identified\n",
      "Fm7/C  | B-7/D  | E-maj7/D  | D/o7/C\n",
      "Am7/C  | E7/D  | E7/D  | CaddD\n",
      "B-7/D  | E-maj7/D  | B-/D  | Cm7\n",
      "B-/D  | A7/C#  | B-/D  | E-addF\n",
      "Gm7/D  | Gm7/D  | Cm7  | B-/C\n",
      "A7/C#  | Dm  | G7/D  | Chord Symbol Cannot Be Identified\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    predict_chords(loaded_model, X_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
