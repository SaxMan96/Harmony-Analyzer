{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utilities import *\n",
    "from music21.harmony import chordSymbolFigureFromChord as figureChord\n",
    "from music21.chord import Chord\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    SAMPLE_LEN = 8\n",
    "    data = [ast.literal_eval(chords_string) for chords_string in df[\"encoded_chords\"]]\n",
    "    # Remove too short songs\n",
    "    data = [chords for chords in data if len(chords) > SAMPLE_LEN]\n",
    "    x = []\n",
    "    y = []\n",
    "    for chords in data:\n",
    "        for i in range(len(chords)):\n",
    "            if i < len(chords) - SAMPLE_LEN:\n",
    "                x.append(chords[i : i + SAMPLE_LEN - 1])\n",
    "            else:\n",
    "                x.append(\n",
    "                    chords[i : len(chords) - 1]\n",
    "                    + chords[: (i + SAMPLE_LEN) % len(chords)]\n",
    "                )\n",
    "            y.append(chords[(i + SAMPLE_LEN) % len(chords)])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "def decode(chord):\n",
    "    if not all(isinstance(x, np.int32) for x in chord):\n",
    "        raise Exception(\n",
    "            \"Expected chord to be array([0, 1, 0, 0 , 1, ...]) instead got: \", chord\n",
    "        )\n",
    "    decoded_chord = []\n",
    "    for counter, value in enumerate(chord):\n",
    "        if value == 1:\n",
    "            decoded_chord.append(counter)\n",
    "    return decoded_chord\n",
    "\n",
    "\n",
    "def print_chords(encoded_chords):\n",
    "    chords_symbols = [figureChord(Chord(decode(chord))) for chord in encoded_chords]\n",
    "    print(*chords_symbols, sep=\"  | \")\n",
    "\n",
    "\n",
    "def threshold_prediction(pred, notes_num):\n",
    "    thresholded_pred = np.zeros(pred.shape, dtype=np.int32)\n",
    "    selected_notes = sorted(range(len(pred)), key=lambda i: pred[i], reverse=True)[\n",
    "        :notes_num\n",
    "    ]\n",
    "    thresholded_pred[selected_notes] = 1\n",
    "    return thresholded_pred\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"models/model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"models/model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "def load_model(json_path, h5_path):\n",
    "    json_file = open(json_path, \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(h5_path)\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def predict_chords(model, input_chords):\n",
    "    pred = model.predict(input_chords[np.newaxis, :, :])[0]\n",
    "    pred = threshold_prediction(pred, 4)\n",
    "    print_chords(np.vstack((input_chords[:3],pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103631, 7, 12) (103631, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"songs_and_chords.csv\")\n",
    "X_train, X_test, y_train, y_test = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 1 0 0 0 1]\n",
      "[2, 5, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][0])\n",
    "print(decode(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM requirements:\n",
    "\n",
    "- The LSTM input layer must be 3D.\n",
    "- LSTMs donâ€™t like sequences of more than 200-400 time steps, so the data will need to be split into samples.\n",
    "- If you have a long sequence of thousands of observations, you must split it into samples and then reshape it for your LSTM model.\n",
    "- The LSTM needs data with the format of [samples, time steps and features].\n",
    "- The LSTM input layer is defined by the input_shape argument on the first hidden layer.\n",
    "- The input_shape argument takes a tuple of two values that define the number of time steps and features.\n",
    "- The number of samples is assumed to be 1 or more.\n",
    "- The reshape() function on NumPy arrays can be used to reshape your 1D or 2D data to be 3D.\n",
    "- The reshape() function takes a tuple as an argument that defines the new shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(7, 12)))\n",
    "# model.add(Dense(12, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(model.summary())\n",
    "# model.fit(X_train, y_train, epochs=3, batch_size=8)\n",
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('models/model.json', \"models/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mateusz\\Miniconda3\\envs\\tf-gpu-env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 32)                5760      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 6,156\n",
      "Trainable params: 6,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 72.68%\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(loaded_model.summary())\n",
    "scores = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-maj7/C  | A#m7/C#  | A-maj7/C  | Fm7/C\n",
      "Fm/C  | Fm/C  | C7  | Fm/CaddB-\n",
      "Gm/D  | B-7/D  | Fm/C  | Gm7/D\n",
      "E-  | A-7/C  | A-7/C  | A-/CaddA\n",
      "Gm7/D  | C7  | F/C  | F/CaddB-\n",
      "E-  | Gm/D  | Cm  | Cm7\n",
      "C7  | F-+/CaddB-  | F/C  | B-/C\n",
      "B-/D  | E-+  | C7  | Chord Symbol Cannot Be Identified\n",
      "F7/C  | B-/D  | B-/D  | B-/C\n",
      "E-m  | A#m7/C#  | E-m  | Chord Symbol Cannot Be Identified\n",
      "Gm7/D  | C7  | F/C  | B-/C\n",
      "D/o7/C  | E-+addF  | Cm7  | B-/C\n",
      "F9/CaddB  | B-7/D  | Cm7addD-,A-,F  | D-maj7/C\n",
      "A7/C#  | D7/C  | D7/C  | Chord Symbol Cannot Be Identified\n",
      "Fm7/C  | B-7/D  | E-maj7/D  | D/o7/C\n",
      "Am7/C  | E7/D  | E7/D  | CaddD\n",
      "B-7/D  | E-maj7/D  | B-/D  | Cm7\n",
      "B-/D  | A7/C#  | B-/D  | E-addF\n",
      "Gm7/D  | Gm7/D  | Cm7  | B-/C\n",
      "A7/C#  | Dm  | G7/D  | Chord Symbol Cannot Be Identified\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    predict_chords(loaded_model, X_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-env]",
   "language": "python",
   "name": "conda-env-tf-gpu-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
